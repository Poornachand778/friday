# AWS g5 (CUDA 12.x) - Stable combo for Llama-3.1 fine-tuning
transformers==4.44.2
torch==2.3.1
accelerate==0.33.0
peft==0.11.1
trl==0.9.6
bitsandbytes==0.43.3
datasets==2.20.0
tokenizers==0.19.1
sentencepiece==0.2.0

# SageMaker dependencies
sagemaker-training
